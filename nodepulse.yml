# NodePulse Agent Configuration

server:
  # The endpoint to send metrics to
  endpoint: "https://ingest.dogfooding.nodepulse.sh"

  # HTTP request timeout
  # If the server doesn't respond within this time, the request fails
  # and the buffered report will be retried later
  timeout: 3s

agent:
  # Unique server ID (UUID format)
  # If not set or left as placeholder, a UUID will be auto-generated on first run
  # and saved to /var/lib/nodepulse/server_id for persistence
  # You can also manually set one: uuidgen (Linux/Mac) or New-Guid (PowerShell)
  server_id: "00000000-0000-0000-0000-000000000000"

  # Default metrics collection interval (fallback for exporters without explicit interval)
  # Valid values: 15s, 30s, 1m
  # Note: Each exporter can override this with its own interval
  interval: 15s

# Prometheus Exporters Configuration
# Phase 2: Each exporter runs independently with its own interval (parallel scraping)
exporters:
  # Node Exporter - System metrics (CPU, memory, disk, network)
  - name: node_exporter
    enabled: true
    endpoint: "http://localhost:9100/metrics"
    interval: 15s  # Optional: Fast scraping for system metrics (falls back to agent.interval if not specified)
    timeout: 3s

  # Process Exporter - Per-process metrics (CPU, memory by process name)
  # NOTE: Requires process_exporter to be installed and running
  # See: ansible/roles/process-exporter/ for deployment
  - name: process_exporter
    enabled: false  # Disabled by default - enable after deploying process_exporter
    endpoint: "http://localhost:9256/metrics"
    interval: 15s  # Same as node_exporter for consistency
    timeout: 3s

  # Example: PostgreSQL Exporter (uncomment to enable)
  # - name: postgres_exporter
  #   enabled: true
  #   endpoint: "http://localhost:9187/metrics"
  #   interval: 30s  # Slower scraping for database metrics
  #   timeout: 5s

  # Example: MySQL Exporter (uncomment to enable)
  # - name: mysql_exporter
  #   enabled: true
  #   endpoint: "http://localhost:9104/metrics"
  #   interval: 30s  # Slower scraping for database metrics
  #   timeout: 5s

  # Example: Redis Exporter (uncomment to enable)
  # - name: redis_exporter
  #   enabled: true
  #   endpoint: "http://localhost:9121/metrics"
  #   interval: 15s  # Fast scraping for cache metrics
  #   timeout: 3s

  # Example: Custom Application Metrics
  # - name: custom_app
  #   enabled: false
  #   endpoint: "http://localhost:8080/metrics"
  #   interval: 1m  # Slow scraping for application metrics
  #   timeout: 5s

buffer:
  # Directory to store buffered reports
  # All metrics are buffered first (Write-Ahead Log pattern)
  # Structure: buffer/<exporter>/YYYYMMDD-HHMMSS-<server_id>.prom
  # Each exporter gets its own subdirectory for better organization
  # Background drain process uses smart batching:
  #   - Groups files by 5s time windows
  #   - Batches multiple exporters scraped at similar times
  #   - Reduces HTTP overhead significantly
  path: "/var/lib/nodepulse/buffer"

  # How long to keep buffered reports (in hours)
  # Files older than this are automatically deleted
  retention_hours: 48

  # Number of reports to send per batch request
  # Phase 2: Increased default for better efficiency with multiple exporters
  # Higher values = fewer HTTP requests, larger payloads
  # Default: 10 (was 5 in Phase 1)
  batch_size: 10

logging:
  # Log level: debug, info, warn, error
  # debug: Verbose diagnostic information for troubleshooting
  # info: General informational messages about normal operation
  # warn: Potentially harmful situations that don't prevent operation
  # error: Error events that might still allow operation to continue
  level: "info"

  # Log output destination: stdout, file, both
  # stdout: Output to console/terminal
  # file: Write to log file with rotation
  # both: Output to both console and file
  output: "stdout"

  # File logging configuration (used when output is "file" or "both")
  file:
    # Path to the log file
    path: "/var/log/nodepulse/agent.log"

    # Maximum size in MB before rotating
    max_size_mb: 10

    # Maximum number of old log files to keep
    max_backups: 3

    # Maximum number of days to keep old log files
    max_age_days: 7

    # Compress rotated log files with gzip
    compress: true
